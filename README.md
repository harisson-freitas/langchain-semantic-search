# Ingest√£o e busca sem√¢ntica com LangChain e Postgres

Sistema de busca sem√¢ntica utilizando RAG (Retrieval-Augmented Generation) com LangChain, PostgreSQL + pgVector para responder perguntas baseadas em documentos PDF.

## Tecnologias

- **Python 3.13+**
- **LangChain** - Framework para aplica√ß√µes com LLM
- **PostgreSQL + pgVector** - Banco de dados vetorial
- **OpenAI / Google Gemini** - Modelos de embeddings e LLM
- **Docker & Docker Compose** - Containeriza√ß√£o

## Pr√©-requisitos

Antes de come√ßar, certifique-se de ter instalado:

### Software necess√°rio

- **Python 3.13 ou superior**
  - Verifique a vers√£o: `python3 --version`
  - Download: [python.org](https://www.python.org/downloads/)

- **pip** (gerenciador de pacotes Python)
  - Geralmente j√° vem com Python
  - Verifique: `pip --version`

- **Docker** e **Docker Compose**
  - Necess√°rio para rodar o PostgreSQL + pgVector
  - Docker Desktop inclui o Docker Compose
  - Download: [docker.com](https://www.docker.com/get-started)
  - Verifique: `docker --version` e `docker compose version`

### Recursos do sistema

- **Porta 5432** dispon√≠vel (usada pelo PostgreSQL)
- **Espa√ßo em disco**: ~500MB m√≠nimo (banco de dados + imagens Docker)
- **Mem√≥ria RAM**: 4GB recomendado

### API Keys

Voc√™ precisar√° de uma conta e API key em **um** dos provedores:

- **OpenAI**
  - Cadastro: [platform.openai.com](https://platform.openai.com)
  - API Keys: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)

- **Google Gemini**
  - Cadastro: [ai.google.dev](https://ai.google.dev)
  - API Keys: [makersuite.google.com/app/apikey](https://makersuite.google.com/app/apikey)

## üîß Configura√ß√£o

### 1. Clone o reposit√≥rio

```bash
git clone <seu-repositorio>
cd langchain-semantic-search
```

### 2. Crie e ative o ambiente virtual

```bash
python3 -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate
```

### 3. Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

### 4. Configure as vari√°veis de ambiente

Copie o arquivo de exemplo e configure suas credenciais:

```bash
cp .env.example .env
```

Edite o arquivo `.env` e adicione sua API Key:

**Para OpenAI:**
```bash
AI_PROVIDER=openai
OPENAI_API_KEY=sua_chave_aqui
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_LLM_MODEL=gpt-5-nano
```

**Para Google Gemini:**
```bash
AI_PROVIDER=google
GOOGLE_API_KEY=sua_chave_aqui
GOOGLE_EMBEDDING_MODEL=models/embedding-001
GOOGLE_LLM_MODEL=gemini-2.5-flash-lite
```

### 5. Adicione seu documento PDF

Coloque o arquivo PDF que deseja processar na raiz do projeto com o nome `document.pdf`

## Execu√ß√£o

### 1. Subir o banco de dados

```bash
docker compose up -d
```

Aguarde alguns segundos para o banco inicializar completamente.

### 2. Executar ingest√£o do PDF

```bash
python src/ingest.py
```

Este comando ir√°:
- Carregar o PDF
- Dividir em chunks de 1000 caracteres
- Gerar embeddings
- Armazenar no banco vetorial

### 3. Rodar o chat

```bash
python src/chat.py
```

## Exemplo de uso

```
============================================================
Sistema de Busca Sem√¢ntica - Chat
Digite sua pergunta ou 'sair' para encerrar.
============================================================

Fa√ßa sua pergunta: Qual o faturamento da Empresa SuperTechIABrazil?

PERGUNTA: Qual o faturamento da Empresa SuperTechIABrazil?

Processando...

RESPOSTA: O faturamento foi de 10 milh√µes de reais.

------------------------------------------------------------

Fa√ßa sua pergunta: Quantos clientes temos em 2024?

PERGUNTA: Quantos clientes temos em 2024?

Processando...

RESPOSTA: N√£o tenho informa√ß√µes necess√°rias para responder sua pergunta.
```

## Parar o banco de dados

```bash
docker compose down
```

Para remover tamb√©m os dados:
```bash
docker compose down -v
```

## Estrutura do projeto

```
.
‚îú‚îÄ‚îÄ docker-compose.yml          # Configura√ß√£o do PostgreSQL + pgVector
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias Python
‚îú‚îÄ‚îÄ .env.example               # Template de vari√°veis de ambiente
‚îú‚îÄ‚îÄ .env                       # Vari√°veis de ambiente (n√£o versionado)
‚îú‚îÄ‚îÄ document.pdf               # PDF para ingest√£o
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           # Inicializa√ß√£o do m√≥dulo
‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Configura√ß√µes e valida√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py             # Script de ingest√£o do PDF
‚îÇ   ‚îú‚îÄ‚îÄ search.py             # Fun√ß√µes de busca sem√¢ntica
‚îÇ   ‚îî‚îÄ‚îÄ chat.py               # Interface CLI
‚îî‚îÄ‚îÄ README.md                  # Este arquivo
```

## Como funciona

1. **Ingest√£o**: O PDF √© carregado e dividido em chunks de 1000 caracteres com overlap de 150
2. **Embeddings**: Cada chunk √© transformado em vetor usando modelo de embeddings
3. **Armazenamento**: Vetores s√£o salvos no PostgreSQL com extens√£o pgVector
4. **Busca**: Pergunta do usu√°rio √© vetorizada e comparada com os chunks (k=10)
5. **Resposta**: Os chunks mais relevantes s√£o enviados como contexto para a LLM gerar a resposta

## Regras de resposta

O sistema responde **apenas** com base no conte√∫do do PDF:
- Se a informa√ß√£o estiver no documento, retorna a resposta
- Se n√£o estiver, retorna: "N√£o tenho informa√ß√µes necess√°rias para responder sua pergunta."
- Nunca inventa ou usa conhecimento externo

## Depend√™ncias principais

- `langchain` - Framework principal
- `langchain-openai` - Integra√ß√£o OpenAI
- `langchain-google-genai` - Integra√ß√£o Google
- `langchain-postgres` - Integra√ß√£o PostgreSQL
- `langchain-community` - Loaders e utilit√°rios
- `pypdf` - Leitura de PDFs
- `pgvector` - Extens√£o vetorial para PostgreSQL

## Troubleshooting

**Erro ao conectar no banco:**
- Verifique se o Docker est√° rodando
- Confirme que a porta 5432 n√£o est√° em uso
- Aguarde alguns segundos ap√≥s `docker compose up`

**Erro de API Key:**
- Verifique se a chave est√° correta no arquivo `.env`
- Confirme que n√£o h√° espa√ßos extras
- Para OpenAI: https://platform.openai.com/api-keys
- Para Google: https://makersuite.google.com/app/apikey

**Erro no import:**
- Ative o ambiente virtual: `source venv/bin/activate`
- Reinstale as depend√™ncias: `pip install -r requirements.txt`

## Licen√ßa

Este projeto foi desenvolvido para fins educacionais.
